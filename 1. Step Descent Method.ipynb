{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm for gradient method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the first part of this notebook, we will use this function\n",
    "\n",
    "q = $ \\frac{1}{2} * x^T * A * x - b * x $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixSize = 10\n",
    "A = np.random.rand(matrixSize, matrixSize)\n",
    "A = np.dot(A, A.transpose())\n",
    "b = np.random.rand(matrixSize, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.516 1.869 2.329 1.406 2.259 2.167 2.102 1.88  2.223 2.316]\n",
      " [1.869 4.099 3.148 1.844 3.836 2.455 3.247 2.48  3.049 2.539]\n",
      " [2.329 3.148 3.841 1.645 3.281 2.896 3.078 2.887 3.049 2.826]\n",
      " [1.406 1.844 1.645 2.626 2.599 1.863 2.617 1.868 1.627 1.566]\n",
      " [2.259 3.836 3.281 2.599 4.322 2.808 3.53  2.706 3.04  2.53 ]\n",
      " [2.167 2.455 2.896 1.863 2.808 2.868 2.869 2.755 2.227 2.691]\n",
      " [2.102 3.247 3.078 2.617 3.53  2.869 4.217 2.64  3.018 2.846]\n",
      " [1.88  2.48  2.887 1.868 2.706 2.755 2.64  3.176 1.89  2.825]\n",
      " [2.223 3.049 3.049 1.627 3.04  2.227 3.018 1.89  3.19  2.316]\n",
      " [2.316 2.539 2.826 1.566 2.53  2.691 2.846 2.825 2.316 3.111]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.187]\n",
      " [0.924]\n",
      " [0.649]\n",
      " [0.194]\n",
      " [0.082]\n",
      " [0.587]\n",
      " [0.041]\n",
      " [0.249]\n",
      " [0.611]\n",
      " [0.158]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    return 0.5 * np.dot(np.dot(x.T, A), x) - np.dot(b.T, x)\n",
    "\n",
    "def model_jac(x):\n",
    "    return np.dot(A, x) - b\n",
    "\n",
    "def model_hess(x):\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_perf(f_value, iteration, h, flag):\n",
    "    \"\"\"\n",
    "        Optimization terminated successfully.\n",
    "         Current function value: 0.000000\n",
    "         Iterations: 339\n",
    "         Function evaluations: 571\n",
    "    \"\"\"\n",
    "    if flag:\n",
    "        print(\"Optimization terminated successfully\")\n",
    "    else:\n",
    "        print(\"No convergence\")\n",
    "    print(f\"Current Gradient Value : {f_value}\")\n",
    "    print(f\"Iterations : {iteration}\")\n",
    "    print(f\"Function evaluations : {h}\")\n",
    "\n",
    "\n",
    "def gradient_descent_method(A, x0, b, eps=1e-3, max_iter=100, gradient=model_jac, hessian=model_hess):\n",
    "    x = x0.copy()\n",
    "    g = gradient(x)\n",
    "    k = 0\n",
    "    while k < max_iter and np.linalg.norm(g) > eps:\n",
    "        alpha = np.dot(g.T, g) / np.dot(np.dot(g.T, hessian(x)), g) # comment inclure ceci ?\n",
    "        x -= alpha * g\n",
    "        g = gradient(x)\n",
    "        k += 1\n",
    "    print_perf(np.linalg.norm(g), k, k+1, np.linalg.norm(g) <= eps)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_method_optimised(A, x0, b, eps=1e-3, max_iter=100, gradient=model_jac, hessian=model_hess):\n",
    "    x = x0.copy()\n",
    "    g = gradient(x)\n",
    "    k = 0\n",
    "    while k < max_iter and np.linalg.norm(g) > eps:\n",
    "        r = np.dot(hessian(x), g)\n",
    "        alpha = (np.dot(g.T, g) / np.dot(g.T, r))\n",
    "        x -= alpha * g\n",
    "        g -= alpha * r\n",
    "        k += 1\n",
    "    print_perf(np.linalg.norm(g), k, k+1, np.linalg.norm(g) <= eps)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.random.rand(matrixSize, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.585]\n",
      " [0.599]\n",
      " [0.59 ]\n",
      " [0.105]\n",
      " [0.392]\n",
      " [0.753]\n",
      " [0.58 ]\n",
      " [0.353]\n",
      " [0.704]\n",
      " [0.164]]\n"
     ]
    }
   ],
   "source": [
    "print(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No convergence\n",
      "Current Gradient Value : 0.41552457963716005\n",
      "Iterations : 100\n",
      "Function evaluations : 101\n"
     ]
    }
   ],
   "source": [
    "xk = gradient_descent_method(A, x0, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.016]\n",
      " [ 2.243]\n",
      " [ 0.289]\n",
      " [ 1.432]\n",
      " [-2.685]\n",
      " [ 2.022]\n",
      " [-1.129]\n",
      " [-0.585]\n",
      " [ 0.356]\n",
      " [-1.002]]\n"
     ]
    }
   ],
   "source": [
    "print(xk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No convergence\n",
      "Current Gradient Value : 0.41552457963726386\n",
      "Iterations : 100\n",
      "Function evaluations : 101\n"
     ]
    }
   ],
   "source": [
    "xk = gradient_descent_method_optimised(A, x0, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.016]\n",
      " [ 2.243]\n",
      " [ 0.289]\n",
      " [ 1.432]\n",
      " [-2.685]\n",
      " [ 2.022]\n",
      " [-1.129]\n",
      " [-0.585]\n",
      " [ 0.356]\n",
      " [-1.002]]\n"
     ]
    }
   ],
   "source": [
    "print(xk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No convergence\n",
      "Current Gradient Value : 0.08009917473126797\n",
      "Iterations : 10000\n",
      "Function evaluations : 10001\n"
     ]
    }
   ],
   "source": [
    "xk = gradient_descent_method_optimised(A, x0, b, max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No convergence\n",
      "Current Gradient Value : 0.011971371068086985\n",
      "Iterations : 50000\n",
      "Function evaluations : 50001\n"
     ]
    }
   ],
   "source": [
    "xk = gradient_descent_method_optimised(A, x0, b, max_iter=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No convergence\n",
      "Current Gradient Value : 0.001112500562532827\n",
      "Iterations : 100000\n",
      "Function evaluations : 100001\n"
     ]
    }
   ],
   "source": [
    "xk = gradient_descent_method_optimised(A, x0, b, max_iter=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on more complex function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosen(x):\n",
    "    \"\"\"The Rosenbrock function\"\"\"\n",
    "    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)\n",
    "\n",
    "def rosen_der(x):\n",
    "    \"\"\"The Rosenbrock Derivative function\"\"\"\n",
    "    xm = x[1:-1]\n",
    "    xm_m1 = x[:-2]\n",
    "    xm_p1 = x[2:]\n",
    "    der = np.zeros_like(x)\n",
    "    der[1:-1] = 200*(xm-xm_m1**2) - 400*(xm_p1 - xm**2)*xm - 2*(1-xm)\n",
    "    der[0] = -400*x[0]*(x[1]-x[0]**2) - 2*(1-x[0])\n",
    "    der[-1] = 200*(x[-1]-x[-2]**2)\n",
    "    return der\n",
    "\n",
    "def rosen_hess(x):\n",
    "    \"\"\"The Rosenbrock Hessian function\"\"\"\n",
    "    x = np.asarray(x)\n",
    "    H = np.diag(-400*x[:-1],1) - np.diag(400*x[:-1],-1)\n",
    "    diagonal = np.zeros_like(x)\n",
    "    diagonal[0] = 1200*x[0]**2-400*x[1]+2\n",
    "    diagonal[-1] = 200\n",
    "    diagonal[1:-1] = 202 + 1200*x[1:-1]**2 - 400*x[2:]\n",
    "    H = H + np.diag(diagonal)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_method(x0, gradient=rosen_der, hessian=rosen_hess, eps=1e-3, max_iter=100):\n",
    "    x = x0.copy()\n",
    "    g = gradient(x)\n",
    "    k = 0\n",
    "    while k < max_iter and np.linalg.norm(g) > eps:\n",
    "        alpha = np.dot(g.T, g) / np.dot(np.dot(g.T, hessian(x)), g) # comment inclure ceci ?\n",
    "        x -= alpha * g\n",
    "        g = gradient(x)\n",
    "        k += 1\n",
    "    print_perf(np.linalg.norm(g), k, k+1, np.linalg.norm(g) <= eps)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.451 1.785 1.151 1.459 1.27  1.115 1.027 1.434 1.083 1.825]\n"
     ]
    }
   ],
   "source": [
    "x0 = np.random.rand(matrixSize)+1\n",
    "print(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1815.7 -580.5    0.     0.     0.     0.     0.     0.     0.     0. ]\n",
      " [-580.5 3563.7 -713.9    0.     0.     0.     0.     0.     0.     0. ]\n",
      " [   0.  -713.9 1208.1 -460.4    0.     0.     0.     0.     0.     0. ]\n",
      " [   0.     0.  -460.4 2247.1 -583.4    0.     0.     0.     0.     0. ]\n",
      " [   0.     0.     0.  -583.4 1691.1 -508.     0.     0.     0.     0. ]\n",
      " [   0.     0.     0.     0.  -508.  1284.5 -446.2    0.     0.     0. ]\n",
      " [   0.     0.     0.     0.     0.  -446.2  892.8 -410.6    0.     0. ]\n",
      " [   0.     0.     0.     0.     0.     0.  -410.6 2236.6 -573.6    0. ]\n",
      " [   0.     0.     0.     0.     0.     0.     0.  -573.6  879.1 -433.1]\n",
      " [   0.     0.     0.     0.     0.     0.     0.     0.  -433.1  200. ]]\n"
     ]
    }
   ],
   "source": [
    "print(rosen_hess(x0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No convergence\n",
      "Current Gradient Value : 0.39445736207433124\n",
      "Iterations : 100\n",
      "Function evaluations : 101\n"
     ]
    }
   ],
   "source": [
    "xk = gradient_descent_method(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No convergence\n",
      "Current Gradient Value : 0.004036129276489186\n",
      "Iterations : 10000\n",
      "Function evaluations : 10001\n"
     ]
    }
   ],
   "source": [
    "xk = gradient_descent_method(x0, max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
